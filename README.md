# MetaLearningPapers
A summary of meta learning papers based on taxonomic category. Sorted by submitted date on arXiv.

## Survey
Meta-Learning[[paper](https://www.ml4aad.org/wp-content/uploads/2018/09/chapter2-metalearning.pdf)]
  - Joaquin Vanschoren

Meta-Learning: A Survey [[paper](https://arxiv.org/pdf/1810.03548.pdf)]
  - Joaquin Vanschoren

Meta-learners’ learning dynamics are unlike learners’  [[paper](https://arxiv.org/pdf/1905.01320.pdf)]
  - Neil C. Rabinowitz

## Few-shot learning
Learning to Learn via Self-Critique [[paper](https://arxiv.org/abs/1905.10295)]
  - Antreas Antoniou, Amos Storkey  --NeurIPS 2019
  
Learning from the Past: Continual Meta-Learning with Bayesian Graph Neural Networks [[paper](https://arxiv.org/abs/1911.04695)]
  - Yadan Luo, Zi Huang, Zheng Zhang, Ziwei Wang, Mahsa Baktashmotlagh, Yang Yang --arXiv 2019

PANet: Few-Shot Image Semantic Segmentation with Prototype Alignment [[paper](https://arxiv.org/abs/1908.06391)]
  - Kaixin Wang, Jun Hao Liew, Yingtian Zou, Daquan Zhou, Jiashi Feng --ICCV 2019

Few-Shot Learning with Global Class Representations [[paper](https://arxiv.org/pdf/1908.05257.pdf)]
  - Tiange Luo, Aoxue Li, Tao Xiang, Weiran Huang, Liwei Wang  --ICCV 2019

TapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning [[paper](https://arxiv.org/pdf/1905.06549.pdf)]
  - Sung Whan Yoon, Jun Seo, Jaekyun Moon --ICML 2019

Learning to Learn with Conditional Class Dependencies  [[paper](https://openreview.net/pdf?id=BJfOXnActQ)]
  - Xiang Jiang, Mohammad Havaei, Farshid Varno, Gabriel Chartrand, Nicolas Chapados, Stan Matwin --ICLR 2019
 
TAFE-Net: Task-Aware Feature Embeddings for Low Shot Learning [[paper](https://arxiv.org/abs/1904.05967)]
  - Xin Wang, Fisher Yu, Ruth Wang, Trevor Darrell, Joseph E. Gonzalez --CVPR 2019

Variational Prototyping-Encoder: One-Shot Learning with Prototypical Images [[paper](https://arxiv.org/abs/1904.08482)]
  - Junsik Kim, Tae-Hyun Oh, Seokju Lee, Fei Pan, In So Kweon --CVPR 2019

LCC: Learning to Customize and Combine Neural Networks for Few-Shot Learning [[paper](https://arxiv.org/pdf/1904.08479.pdf)]
  - Yaoyao Liu, Qianru Sun, An-An Liu, Yuting Su, Bernt Schiele, Tat-Seng Chua --CVPR 2019

Meta-Learning with Differentiable Convex Optimization [[paper](https://arxiv.org/abs/1904.03758)]
  - Kwonjoon Lee, Subhransu Maji, Avinash Ravichandran, Stefano Soatto --CVPR 2019

Dense Classification and Implanting for Few-Shot Learning [[paper](https://arxiv.org/pdf/1903.05050.pdf)]
  - Yann Lifchitz, Yannis Avrithis, Sylvaine Picard, Andrei Bursuc --CVPR 2019

Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples
  - Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Kelvin Xu, Ross Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine Manzagol, Hugo Larochelle  -- arXiv 2019
 
Adaptive Cross-Modal Few-Shot Learning [[paper](https://arxiv.org/pdf/1902.07104.pdf)]
  - Chen Xing, Negar Rostamzadeh, Boris N. Oreshkin, Pedro O. Pinheiro --arXiv 2019

Meta-Learning with Latent Embedding Optimization [[paper](https://arxiv.org/abs/1807.05960)]
  - Andrei A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu, Simon Osindero, Raia Hadsell -- ICLR 2019
 
A Closer Look at Few-shot Classification [[paper](https://arxiv.org/abs/1904.04232)]
  - Wei-Yu Chen, Yen-Cheng Liu, Zsolt Kira, Yu-Chiang Frank Wang, Jia-Bin Huang  -- ICLR 2019
 
Learning to Propagate Labels: Transductive Propagation Network for Few-shot Learning [[paper](https://arxiv.org/pdf/1805.10002.pdf)]
  - Yanbin Liu, Juho Lee, Minseop Park, Saehoon Kim, Eunho Yang, Sung Ju Hwang, Yi Yang -- ICLR 2019

Dynamic Few-Shot Visual Learning without Forgetting [[paper](https://arxiv.org/pdf/1804.09458v1.pdf)]
  - Spyros Gidaris, Nikos Komodakis --arXiv 2019

Meta Learning with Lantent Embedding Optimization [[paper](https://openreview.net/pdf?id=BJgklhAcK7)]
  - Andrei A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu, Simon Osindero & Raia Hadsell --ICLR 2019

Adaptive Posterior Learning: few-shot learning with a surprise-based memory module
  - Tiago Ramalho, Marta Garnelo --ICLR 2019

How To Train Your MAML [[paper](https://arxiv.org/pdf/1810.09502v1.pdf)]
  - Antreas Antoniou, Harrison Edwards, Amos Storkey -- ICLR 2019

TADAM: Task dependent adaptive metric for improved few-shot learning [[paper](https://arxiv.org/abs/1805.10123)]
  - Boris N. Oreshkin, Pau Rodriguez, Alexandre Lacoste --arXiv 2019

Few-shot Learning with Meta Metric Learners
  - Yu Cheng, Mo Yu, Xiaoxiao Guo, Bowen Zhou --NIPS 2017 workshop on Meta-Learning

Learning Embedding Adaptation for Few-Shot Learning [[paper](https://arxiv.org/pdf/1812.03664.pdf)]
  - Han-Jia Ye, Hexiang Hu, De-Chuan Zhan, Fei Sha --arXiv 2018

Meta-Transfer Learning for Few-Shot Learning [[paper](https://arxiv.org/pdf/1812.02391.pdf)]
  - Qianru Sun, Yaoyao Liu, Tat-Seng Chu, Bernt Schiele -- arXiv 2018

Task-Agnostic Meta-Learning for Few-shot Learning
  - Muhammad Abdullah Jamal, Guo-Jun Qi, and Mubarak Shah  --arXiv 2018

Few-Shot Learning with Graph Neural Networks [[paper](https://arxiv.org/abs/1711.04043)]
  - Victor Garcia, Joan Bruna -- ICLR 2018

Prototypical Networks for Few-shot Learning [[paper](https://arxiv.org/pdf/1703.05175.pdf)]
  - Jake Snell, Kevin Swersky, Richard S. Zemel -- NIPS 2017
  
Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks [[paper](https://arxiv.org/abs/1703.03400)]
  - Chelsea Finn, Pieter Abbeel, Sergey Levine -- ICML 2016

### Large scale dataset
Image Deformation Meta-Networks for One-Shot Learning [[paper](https://arxiv.org/pdf/1905.11641.pdf)]
  - Zitian Chen, Yanwei Fu, Yu-Xiong Wang, Lin Ma, Wei Liu, Martial Hebert --CVPR 2019

### Imbalance class
Learning to Model the Tail [[paper](https://papers.nips.cc/paper/7278-learning-to-model-the-tail.pdf)]
  - Yu-Xiong Wang, Deva Ramanan, Martial Hebert --NeurIPS 2017

### NLP
Learning to Few-Shot Learn Across Diverse Natural Language Classification Tasks [[paper](https://arxiv.org/pdf/1911.03863.pdf)]
  - Trapit Bansal, Rishikesh Jha, Andrew McCallum  --arXiv 

Few-Shot Representation Learning for Out-Of-Vocabulary Words [[paper](https://arxiv.org/abs/1907.00505)]
  - Ziniu Hu, Ting Chen, Kai-Wei Chang, Yizhou Sun --ACL 2019

## Reinforcement learning
Guided Meta-Policy Search [[paper](https://arxiv.org/abs/1904.00956)]
  - Russell Mendonca, Abhishek Gupta, Rosen Kralev, Pieter Abbeel, Sergey Levine, Chelsea Finn

## Architecture search
Graph HyperNetworks for Neural Architecture Search [[paper](https://arxiv.org/abs/1810.05749)]
  - Chris Zhang, Mengye Ren, Raquel Urtasun --ICLR 2019

Fast Task-Aware Architecture Inference
  - Efi Kokiopoulou, Anja Hauth, Luciano Sbaiz, Andrea Gesmundo, Gabor Bartok, Jesse Berent --arXiv 2019

Bayesian Meta-network Architecture Learning
  - Albert Shaw, Bo Dai, Weiyang Liu, Le Song --arXiv 2018
  
## Task-dependent

Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation [[paper](https://arxiv.org/abs/1910.13616)]
  - Risto Vuorio, Shao-Hua Sun, Hexiang Hu, Joseph J. Lim --NeurIPS 2019

Meta-Learning with Warped Gradient Descent [[paper](https://arxiv.org/pdf/1909.00025.pdf)]
  - Sebastian Flennerhag, Andrei A. Rusu, Razvan Pascanu, Hujun Yin, Raia Hadsell --arXiv 2019

TAFE-Net: Task-Aware Feature Embeddings for Low Shot Learning [[paper](https://arxiv.org/abs/1904.05967)]
  - Xin Wang, Fisher Yu, Ruth Wang, Trevor Darrell, Joseph E. Gonzalez --CVPR 2019

TapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning [[paper](https://arxiv.org/pdf/1905.06549.pdf)]
  - Sung Whan Yoon, Jun Seo, Jaekyun Moon --ICML 2019

Meta-Learning with Latent Embedding Optimization [[paper](https://arxiv.org/abs/1807.05960)]
  - Andrei A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu, Simon Osindero, Raia Hadsell -- ICLR 2019

Fast Task-Aware Architecture Inference
  - Efi Kokiopoulou, Anja Hauth, Luciano Sbaiz, Andrea Gesmundo, Gabor Bartok, Jesse Berent --arXiv 2019

Task2Vec: Task Embedding for Meta-Learning
  - Alessandro Achille, Michael Lam, Rahul Tewari, Avinash Ravichandran, Subhransu Maji, Charless Fowlkes, Stefano Soatto, Pietro Perona--arXiv 2019

TADAM: Task dependent adaptive metric for improved few-shot learning
  - Boris N. Oreshkin, Pau Rodriguez, Alexandre Lacoste --arXiv 2019
  
MetaReg: Towards Domain Generalization using Meta-Regularization [[paper](https://papers.nips.cc/paper/7378-metareg-towards-domain-generalization-using-meta-regularization.pdf)]
  - Yogesh Balaji, Swami Sankaranarayanan -- NIPS 2018

### Heterogeneous task
Statistical Model Aggregation via Parameter Matching [[paper]](https://arxiv.org/pdf/1911.00218.pdf)
  - Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald, Trong Nghia Hoang --NeurIPS 2019

Hierarchically Structured Meta-learning [[paper](https://arxiv.org/pdf/1905.05301.pdf)]
  - Huaxiu Yao, Ying Wei, Junzhou Huang, Zhenhui Li --ICML 2019

Hierarchical Meta Learning [[paper](https://arxiv.org/abs/1904.09081)]
  - Yingtian Zou, Jiashi Feng  --arXiv 2019

## Lifelong learning
Online-Within-Online Meta-Learning [[paper](https://papers.nips.cc/paper/9468-online-within-online-meta-learning)]
  - Giulia Denevi, Dimitris Stamos, Carlo Ciliberto, Massimiliano Pontil
  
Reconciling meta-learning and continual learning with online mixtures of tasks [[paper](https://arxiv.org/abs/1812.06080)]
  - Ghassen Jerfel, Erin Grant, Thomas L. Griffiths, Katherine Heller  --NeurIPS 2019

Meta-Learning Representations for Continual Learning [[paper](https://arxiv.org/abs/1905.12588)]
  - Khurram Javed, Martha White  --NeurIPS 2019

Online Meta-Learning [[paper](https://arxiv.org/abs/1902.08438)]
  - Chelsea Finn, Aravind Rajeswaran, Sham Kakade, Sergey Levine  --ICML 2019

Hierarchically Structured Meta-learning [[paper](https://arxiv.org/pdf/1905.05301.pdf)]
  - Huaxiu Yao, Ying Wei, Junzhou Huang, Zhenhui Li --ICML 2019

A Neural-Symbolic Architecture for Inverse Graphics Improved by Lifelong Meta-Learning [[paper](https://arxiv.org/pdf/1905.08910.pdf)]
  - Michael Kissner, Helmut Mayer --arXiv 2019

Incremental Learning-to-Learn with Statistical Guarantees [[paper](http://auai.org/uai2018/proceedings/papers/181.pdf)]
  - Giulia Denevi, Carlo Ciliberto, Dimitris Stamos, Massimiliano Pontil --arXiv 2018
  
## Domain generation
Domain Generalization via Model-Agnostic Learning of Semantic Features [[paper](https://arxiv.org/abs/1910.13580)]
  - Qi Dou, Daniel C. Castro, Konstantinos Kamnitsas, Ben Glocker
  
Learning to Generalize: Meta-Learning for Domain Generalization
  - Da Li, Yongxin Yang, Yi-Zhe Song, Timothy M. Hospedales -- arXiv 2018

## Bayesian inference
Meta-Amortized Variational Inference and Learning [[paper](https://arxiv.org/pdf/1902.01950.pdf)]
  - Mike Wu, Kristy Choi, Noah Goodman, Stefano Ermon  --arXiv 2019

Amortized Bayesian Meta-Learning [[paper](https://openreview.net/pdf?id=rkgpy3C5tX)]
  - Sachin Ravi, Alex Beatson --ICLR 2019

Meta-Learning Priors for Efficient Online Bayesian Regression [[paper](https://arxiv.org/abs/1807.08912)]
  - James Harrison, Apoorva Sharma, Marco Pavone --WAFR 2018

Probabilistic Model-Agnostic Meta-Learning [[paper](https://arxiv.org/pdf/1806.02817.pdf)]
  - Chelsea Finn, Kelvin Xu, Sergey Levine  --arXiv 2018

Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions [[paper](https://arxiv.org/abs/1710.10304)]
  - Scott Reed, Yutian Chen, Thomas Paine, Aäron van den Oord, S. M. Ali Eslami, Danilo Rezende, Oriol Vinyals, Nando de Freitas --ICLR 2018

Bayesian Model-Agnostic Meta-Learning [[paper](https://arxiv.org/abs/1806.03836)]
  - Taesup Kim, Jaesik Yoon, Ousmane Dia, Sungwoong Kim, Yoshua Bengio, Sungjin Ahn -- NIPS 2018

Meta-learning by adjusting priors based on extended PAC-Bayes theory [[paper](https://arxiv.org/pdf/1711.01244.pdf)]
  - Ron Amit , Ron Meir --ICML 2018

## Learning curves
Meta-Curvature [[paper](https://arxiv.org/abs/1902.03356)]
  - Eunbyung Park, Junier B. Oliva --NeurIPS 2019
  
## Configuration transfer

Fast Context Adaptation via Meta-Learning [[paper](https://arxiv.org/pdf/1810.03642.pdf)]
  - Luisa M Zintgraf, Kyriacos Shiarlis, Vitaly Kurin, Katja Hofmann, Shimon Whiteson  --ICML 2019

Zero-Shot Knowledge Distillation in Deep Networks [[paper](https://arxiv.org/pdf/1905.08114.pdf)]
  - Gaurav Kumar Nayak *, Konda Reddy Mopuri, Vaisakh Shaj, R. Venkatesh Babu, Anirban Chakraborty --ICML 2019

Toward Multimodal Model-Agnostic Meta-Learning [[paper](https://arxiv.org/pdf/1812.07172.pdf)]
  - Risto Vuorio, Shao-Hua Sun, Hexiang Hu, Joseph J. Lim  --arXiv 2019

### Unsupervised learning
Unsupervised Learning via Meta-Learning [[paper](https://arxiv.org/abs/1810.02334)]
  - Kyle Hsu, Sergey Levine, Chelsea Finn -- ICLR 2019
  
Meta-Learning Update Rules for Unsupervised Representation Learning [[paper](https://openreview.net/pdf?id=HkNDsiC9KQ)]
  - Luke Metz, Niru Maheswaranathan, Brian Cheung, Jascha Sohl-Dickstein --ICLR 2019

Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace [[paper](https://arxiv.org/abs/1903.08254)]
  - Kate Rakelly, Aurick Zhou, Deirdre Quillen, Chelsea Finn, Sergey Levine  --ICML 2018

## Hyperparameter
LCC: Learning to Customize and Combine Neural Networks for Few-Shot Learning [[paper](https://arxiv.org/pdf/1904.08479.pdf)]
  - Yaoyao Liu, Qianru Sun, An-An Liu, Yuting Su, Bernt Schiele, Tat-Seng Chua --CVPR 2019

Gradient-based Hyperparameter Optimization through Reversible Learning [[paper](https://arxiv.org/pdf/1502.03492.pdf)]
  - Dougal Maclaurin, David Duvenaud, Ryan P. Adams --ICML 2016

## Model compression
N2N Learning: Network to Network Compression via Policy Gradient Reinforcement Learning
  - Anubhav Ashok, Nicholas Rhinehart, Fares Beainy, Kris M. Kitani --ICLR 2018

## Kernel learning
Deep Mean Functions for Meta-Learning in Gaussian Processes [[paper](https://arxiv.org/pdf/1901.08098.pdf)]
  - Vincent Fortuin, Gunnar Rätsch --arXiv 2019

Kernel Learning and Meta Kernels for Transfer Learning  [[paper](http://www1.icsi.berkeley.edu/~rueckert/papers/rueckert09kernel)]
  - Ulrich Ruckert

## Optimization
MetaInit: Initializing learning by learning to initialize [[paper](https://papers.nips.cc/paper/9427-metainit-initializing-learning-by-learning-to-initialize)]
  - Yann N. Dauphin, Samuel Schoenholz  --NeurIPS 2019
  
Meta-Learning with Implicit Gradients [[paper](https://arxiv.org/abs/1909.04630)]
  - Aravind Rajeswaran*, Chelsea Finn*, Sham Kakade, Sergey Levine  --NeurIPS 2019

Model-Agnostic Meta-Learning using Runge-Kutta Methods [[paper](https://arxiv.org/abs/1910.07368)]
  - Daniel Jiwoong Im, Yibo Jiang, Nakul Verma --arXiv

Learning to Optimize in Swarms [[paper](https://arxiv.org/pdf/1911.03787.pdf)]
  - Yue Cao, Tianlong Chen, Zhangyang Wang, Yang Shen --arXiv 2019

Meta-Learning with Warped Gradient Descent [[paper](https://arxiv.org/pdf/1909.00025.pdf)]
  - Sebastian Flennerhag, Andrei A. Rusu, Razvan Pascanu, Hujun Yin, Raia Hadsell --arXiv 2019
  
Learning to Generalize to Unseen Tasks with Bilevel Optimization [[paper](https://arxiv.org/pdf/1908.01457.pdf)]
  - Hayeon Lee, Donghyun Na, Hae Beom Lee, Sung Ju Hwang --arXiv 2019

Learning to Optimize [[paper](https://arxiv.org/abs/1606.01885)]
  - Ke Li Jitendra Malik --ICLR 2017

Gradient-based Hyperparameter Optimization through Reversible Learning [[paper](https://arxiv.org/pdf/1502.03492.pdf)]
  - Dougal Maclaurin, David Duvenaud, Ryan P. Adams --ICML 2016

## Theory
Efficient Meta Learning via Minibatch Proximal Update [[paper](https://papers.nips.cc/paper/8432-efficient-meta-learning-via-minibatch-proximal-update)]
  - Pan Zhou, Xiaotong Yuan, Huan Xu, Shuicheng Yan, Jiashi Feng --NeurIPS 2019

On the Convergence Theory of Gradient-Based Model-Agnostic Meta-Learning Algorithms [[paper](https://arxiv.org/pdf/1908.10400.pdf)]
  - Alireza Fallah, Aryan Mokhtari, Asuman Ozdaglar --arXiv 2019

Meta-learners' learning dynamics are unlike learners' [[paper](https://arxiv.org/abs/1905.01320)]
  - Neil C. Rabinowitz --arXiv 2019

Regret bounds for meta Bayesian optimization with an unknown Gaussian process prior [[paper](https://arxiv.org/pdf/1811.09558.pdf)]
  - Zi Wang, Beomjoon Kim, Leslie Pack Kaelbling --NeurIPS 2018

Incremental Learning-to-Learn with Statistical Guarantees [[paper](https://arxiv.org/abs/1803.08089)]
  - Giulia Denevi, Carlo Ciliberto, Dimitris Stamos, Massimiliano Pontil  --UAI 2018

Meta-learning by adjusting priors based on extended PAC-Bayes theory [[paper](https://arxiv.org/pdf/1711.01244.pdf)]
  - Ron Amit , Ron Meir --ICML 2018

Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm [[paper](https://arxiv.org/pdf/1710.11622.pdf)]
  - Chelsea Finn, Sergey Levine --ICLR 2018

On the Convergence of Model-Agnostic Meta-Learning [[paper](http://noahgolmant.com/writings/maml.pdf)]
  - Noah Golmant

Fast Rates by Transferring from Auxiliary Hypotheses [[paper](https://arxiv.org/pdf/1412.1619.pdf)]
  - Ilja Kuzborskij, Francesco Orabona --arXiv 2014

Algorithmic Stability and Meta-Learning  [[paper](http://www.jmlr.org/papers/volume6/maurer05a/maurer05a.pdf)]
  - Andreas Maurer  --JMLR 2005

### Online convex optimization
Online Meta-Learning on Non-convex Setting [[paper](https://arxiv.org/abs/1910.10196)]
  - Zhenxun Zhuang, Yunlong Wang, Kezi Yu, Songtao Lu --arXiv 2019

Adaptive Gradient-Based Meta-Learning Methods [[paper](https://arxiv.org/pdf/1906.02717.pdf)]
  - Mikhail Khodak, Maria-Florina Balcan, Ameet Talwalkar --NeurIPS 2019

Learning-to-Learn Stochastic Gradient Descent with Biased Regularization [[paper](https://arxiv.org/abs/1903.10399)]
  - Giulia Denevi, Carlo Ciliberto, Riccardo Grazzi, Massimiliano Pontil  --NeurIPS 2019

Provable Guarantees for Gradient-Based Meta-Learning
  -  Mikhail Khodak Maria-Florina Balcan Ameet Talwalkar --arXiv 2019 
